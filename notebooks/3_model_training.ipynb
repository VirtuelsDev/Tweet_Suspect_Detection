{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les fonctions nécessaires depuis le package src\n",
    "from src import load_data, vectorize_text, train_model, save_model\n",
    "\n",
    "# Charger les données prétraitées\n",
    "df = load_data('../data/processed_data.csv')\n",
    "\n",
    "# Vectoriser les tweets en utilisant TF-IDF\n",
    "X, vectorizer = vectorize_text(df['cleaned_tweet'], method='tfidf', max_features=1000)\n",
    "\n",
    "# Sauvegarder le vectoriseur pour une utilisation ultérieure\n",
    "save_model(vectorizer, '../models/tfidf_vectorizer.pkl')\n",
    "\n",
    "# Définir les étiquettes\n",
    "y = df['label']\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraîner les modèles\n",
    "model_types = ['logistic', 'nb', 'svm', 'rf']\n",
    "trained_models = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f\"Entraînement du modèle: {model_type}\")\n",
    "    model = train_model(X_train, y_train, model_type=model_type)\n",
    "    trained_models[model_type] = model\n",
    "    # Sauvegarder chaque modèle\n",
    "    save_model(model, f'../models/{model_type}_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>awww thats a bummer  you shoulda got david ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>i dived many times for the ball managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>no its not behaving at all im mad why am i he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  tweet_length  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...      1           115   \n",
       "1  is upset that he can't update his Facebook by ...      1           111   \n",
       "2  @Kenichan I dived many times for the ball. Man...      1            89   \n",
       "3    my whole body feels itchy and like its on fire       0            47   \n",
       "4  @nationwideclass no, it's not behaving at all....      1           111   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0     awww thats a bummer  you shoulda got david ...  \n",
       "1  is upset that he cant update his facebook by t...  \n",
       "2   i dived many times for the ball managed to sa...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4   no its not behaving at all im mad why am i he...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le DataFrame à partir du fichier pickle\n",
    "df = pd.read_pickle('df_data_cleaned.pkl')\n",
    "\n",
    "# Afficher les premières lignes pour vérifier que les données sont chargées\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation des tweets nettoyés en utilisant TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Appliquer TF-IDF sur les tweets nettoyés\n",
    "X = tfidf_vectorizer.fit_transform(df['cleaned_tweet'])  # Assurez-vous que 'cleaned_tweet' est la bonne colonne\n",
    "y = df['label']  # Label de la classification\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test (80% - 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des modèles à entraîner\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Support Vector Machine (SVM)\": SVC(kernel='linear')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle: Logistic Regression\n",
      "Évaluation du modèle Logistic Regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.45      0.62      1222\n",
      "           1       0.94      1.00      0.97     10778\n",
      "\n",
      "    accuracy                           0.94     12000\n",
      "   macro avg       0.96      0.73      0.79     12000\n",
      "weighted avg       0.95      0.94      0.93     12000\n",
      "\n",
      "Matrice de confusion :\n",
      "[[  552   670]\n",
      " [    8 10770]]\n",
      "\n",
      "============================================================\n",
      "Entraînement du modèle: Naive Bayes\n",
      "Évaluation du modèle Naive Bayes :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.04      0.07      1222\n",
      "           1       0.90      1.00      0.95     10778\n",
      "\n",
      "    accuracy                           0.90     12000\n",
      "   macro avg       0.89      0.52      0.51     12000\n",
      "weighted avg       0.90      0.90      0.86     12000\n",
      "\n",
      "Matrice de confusion :\n",
      "[[   47  1175]\n",
      " [    6 10772]]\n",
      "\n",
      "============================================================\n",
      "Entraînement du modèle: Support Vector Machine (SVM)\n",
      "Évaluation du modèle Support Vector Machine (SVM) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.86      1222\n",
      "           1       0.97      1.00      0.99     10778\n",
      "\n",
      "    accuracy                           0.97     12000\n",
      "   macro avg       0.97      0.88      0.92     12000\n",
      "weighted avg       0.97      0.97      0.97     12000\n",
      "\n",
      "Matrice de confusion :\n",
      "[[  932   290]\n",
      " [   26 10752]]\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Entraînement et évaluation des modèles\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Entraînement du modèle: {model_name}\")\n",
    "    \n",
    "    # Entraînement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    print(f\"Évaluation du modèle {model_name} :\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Matrice de confusion :\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation des hyperparamètres avec GridSearchCV (exemple pour le SVM)\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation des hyperparamètres pour le modèle SVM avec GridSearchCV\n"
     ]
    }
   ],
   "source": [
    "# Recherche de grille pour SVM\n",
    "print(\"Optimisation des hyperparamètres pour le modèle SVM avec GridSearchCV\")\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des meilleurs paramètres\n",
    "print(\"Meilleurs paramètres trouvés pour SVM :\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement avec les meilleurs paramètres\n",
    "best_svm_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions avec le meilleur modèle\n",
    "y_pred_best_svm = best_svm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle optimisé\n",
    "print(\"\\nÉvaluation du modèle SVM optimisé :\")\n",
    "print(classification_report(y_test, y_pred_best_svm))\n",
    "print(\"Matrice de confusion (SVM optimisé) :\")\n",
    "print(confusion_matrix(y_test, y_pred_best_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Description des étapes**\n",
    "\n",
    "1. **Chargement des données** :\n",
    "   - Les données prétraitées (tweets nettoyés) sont chargées dans un dataframe `df`. Vous pouvez utiliser `pd.read_csv()` ou tout autre moyen pour charger vos données.\n",
    "   \n",
    "2. **Vectorisation avec TF-IDF** :\n",
    "   - Nous utilisons `TfidfVectorizer` de `sklearn` pour transformer les tweets nettoyés en une matrice de caractéristiques numériques. Cette transformation est importante, car elle permet de convertir les mots en une représentation vectorielle que les modèles de machine learning peuvent comprendre.\n",
    "   \n",
    "3. **Séparation des données en ensembles d'entraînement et de test** :\n",
    "   - Nous divisons les données en un ensemble d'entraînement (80%) et un ensemble de test (20%) en utilisant `train_test_split`. L'objectif est de tester le modèle sur des données qu'il n'a jamais vues pour évaluer sa capacité à généraliser.\n",
    "\n",
    "4. **Entraînement des modèles** :\n",
    "   - Trois modèles différents sont entraînés : \n",
    "     - **Régression logistique** (`LogisticRegression`), idéale pour les tâches de classification binaire.\n",
    "     - **Naive Bayes** (`MultinomialNB`), efficace pour les données textuelles.\n",
    "     - **Support Vector Machine** (`SVC`), une option puissante pour la classification.\n",
    "   - Pour chaque modèle, nous affichons un **rapport de classification** (`classification_report`) qui inclut des mesures comme la précision, le rappel et la F1-score, ainsi qu'une **matrice de confusion** pour visualiser la performance du modèle.\n",
    "\n",
    "5. **Optimisation des hyperparamètres** :\n",
    "   - **GridSearchCV** est utilisé pour effectuer une recherche sur une grille d'hyperparamètres afin d'optimiser le modèle SVM. Cette étape permet de trouver les meilleurs paramètres pour le modèle, comme le paramètre `C`, le type de noyau (`kernel`), et `gamma`.\n",
    "\n",
    "6. **Sauvegarde du modèle et du vectoriseur** :\n",
    "   - Après avoir formé le modèle optimisé, nous sauvegardons le modèle entraîné et le vectoriseur TF-IDF à l'aide de `joblib.dump`. Cela permet de réutiliser le modèle dans de futures prédictions sans avoir à l'entraîner à nouveau.\n",
    "\n",
    "### **Métriques utilisées pour l'évaluation somaire** :\n",
    "\n",
    "- **Précision** : Proportion des prédictions correctes parmi toutes les prédictions faites.\n",
    "- **Rappel** : Proportion des vraies positives parmi les éléments qui étaient réellement positifs.\n",
    "- **F1-Score** : La moyenne harmonique entre la précision et le rappel. Une bonne mesure pour les classes déséquilibrées.\n",
    "- **Matrice de confusion** : Une matrice qui résume les résultats des prédictions avec les classes prédites versus les classes réelles.\n",
    "\n",
    "### **Conclusion** :\n",
    "Le notebook `3_model_training.ipynb` vous guide à travers l'entraînement et l'évaluation de plusieurs modèles de classification pour votre tâche de prédiction basée sur des tweets. Vous pouvez facilement ajouter ou modifier des modèles ou optimiser davantage les hyperparamètres pour améliorer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle entraîné et le vectoriseur pour réutilisation\n",
    "import joblib\n",
    "\n",
    "# Sauvegarder le meilleur modèle\n",
    "joblib.dump(best_svm_model, 'best_svm_model.pkl')\n",
    "\n",
    "# Sauvegarder le vectoriseur TF-IDF\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
